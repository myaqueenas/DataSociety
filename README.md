# DataSociety
## Discuss the challenges you may experience as a professional data scientist when trying to create knowledge using data science techniques in ethical and legally appropriate ways.
### Youngjin Noh

### Introductions
Data science is focused on discovering and creating knowledge from data in a wide variety of fields, and it is becoming increasingly influential in society (Maneth & Poulovassilis, 2017). Also, Big data is also generated at an incredible rate and is characterized by an ample variety of data (Menichelli & Kitchin, 2015). With this data science receiving social attention, data ethics in a new area of research and moral issues evaluation also emerge (Floridi & Taddeo, 2016). In line with this trend, European Union, developed countries and global organizations have enacted or agreed upon data privacy laws or agreements. However, there are no such legal requirements yet in a number of Asian countries and Third World countries (Marelli & Testa, 2018; Greenleaf, 2014; “OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data”, n.d.). These legal and ethical responsibilities of data scientists can no longer be overlooked in the process of data scientists collecting and creating knowledge through data science and these responsibilities are closely related to their challenges (Floridi & Taddeo, 2016). This essay will focus on data validity, privacy and data legislation, including examples and various aspects of challenges that data scientists face when creating knowledge with data science.

### Data validity (Electronic Recruitment System)
Determining the validity of data in Electronic Recruitment System is one of the challenges of data scientists. Recently, there are growing number of people who uses the web services such as LinkedIn, one of employment matching services operated via mobile and web sites, and a number of companies are also using Electronic Recruitment System to hire employees which automates the process of receiving resumes of applicants (Faliagka et al., 2015). As such Electronic Recruitment System which uses the data science, allow easier access between the participants and the companies, the number of companies which operate through such systems increases which may suggest that it contains several advantages such as saving time and money. The companies may not consider this as an unfair process of the employment, rather, they believe that the system would find the most suitable employees for themselves (Pfieffelmann et al., 2010; Viswesvaran, 2003). Despite these practical benefits, Electronic Recruitment System faces new challenges for human resource management data scientists (Jones & Dages, 2003). In addition, While Electronic Recruitment System is widely accepted by businesses, there are arguable issues regarding Electronic Recruitment System remain unresolved (Sylva & Mol, 2009). For instance, even today, personalities of the candidates could not still have been fully understood and evaluated through the Electronic Recruitment System. The character of candidates is a matter to be addressed in interviews, not in data analysis (Faliagka et al., 2015). Data validity means that the data is accurate and useful for its purpose, which is difficult for data scientists to see that some data of the applicant is accurate and valid for recruitment (Di Zio et al., 2017). Also problematic is how much this data analytics system is reflected in recruitment. For example, it has been revealed that Amazon, one of the world largest online retail conglomerates discriminates against women in its Electronic Recruitment System process. Electronic Recruitment System of Amazon uses artificial intelligence to evaluate each of entries of candidates and hire the top five. However, the company did not assess the gender of the applicants in a neutral manner. This is because the artificial intelligence has focused on the pattern of resumes submitted over the past decade. Since online retail is a male-intensive industry, the artificial intelligence determined that men were better suited for the company than women. Amazon recruiter said it has solved the problem and that it is committed to diversity and equality in the hiring process, but some people have expressed concern that there may be another form of discrimination in the Electronic Recruitment System in the future. Discrimination against gender was not the only problem. Unqualified candidates are often recommended for jobs. This event illustrates the limitations of current machine learning technology (Amazon ditched AI recruiting tool that favored men for technical jobs, 2018). In fact, all Electronic Recruitment System cannot be avoided, and all companies cannot adopt outdated recruitment methods such as interviewing. Determining the validity of data in the current system is one of the challenges of data scientists. As technology advances and new systems are developed, data scientists and companies would have to be more careful in applying them to their field and business, and problems caused by new technologies and systems would have to be corrected soon. However, it could be ethically controversial for artificial intelligence and data science to assess human values. In some cases, the scope of social media activities of individual is reflected in the Electronic Recruitment System and it can be developed to infringe upon and discriminate against this privacy of individual. The second topic in this essay is about privacy and more details follow.

### Privacy
Surveillance technology has developed to the point where bio-metric technology has been built in recent years. Surveillance cameras system are also rampant in the United Kingdom, with more than 4.2 million cameras set up to collect various data (Norris & Mccahill, 2006). However, In the process of mining data through observation and surveillance, data scientists may inevitably face challenges regarding privacy (Williams & Johnstone, 2000). Surveillance cameras system is a representative tool for collecting data through investigation and observation (Davies, 2016; Grindrod, 2016). Some researchers note the effectiveness of surveillance cameras system for public benefits (Welsh et al., 2002; Kroene, 2013). According to Kroene (2013), surveillance camera systems in the city centre not only monitor weather, traffic and pollution for research, but also play a major role in preventing terrorism. He was also quoted as saying that surveillance cameras system played a big role in the arrest of suspects in London underground bombing. Also, the presence and installation of surveillance cameras can also deter and prevent terrorism. However, there are not only positive effects of surveillance of data. While it could be impossible for researchers or governments to obtain authority over everyone's data collection, it may be a controversial topic for them to justify their actions ethically, simply because they have access to privacy data and are for public order (Boyd & Crawford, 2012). These controversies and issues are seen primarily in Asian countries or the third world than in European countries and developed countries where data and privacy laws are strengthened (Greenleaf, 2014). For example, anonymity and privacy are special issues these days in Hong Kong (Hu, 2019; Cheng et al., 2012). The facial mask, which covers more than half of the face, has become a representative uniform of pro-democracy demonstrators who fill the streets. Some Hong Kong citizens are concerned that Mainland China government would be used to quell protests using face recognition of surveillance cameras system for political purposes, not for civil safety. Therefore, Hong Kong citizens participating in the protests are extremely reluctant to reveal their faces or identities (Hu, 2019). Looking at the Hong Kong case, data science may be used as a means to maintain their power. (Norris et al., 2016). Furthermore, the challenge for data scientist related privacy was not only found in Asian countries, but also in Chicago, the United States, where privacy and data laws advanced. Saunders et al. (2016) claims that Chicago police used data to anticipate who might be criminals in 2013. This method is a predictive model that uses algorithms to identify criminal risk cases and is a relevant prevention strategy to reduce these risks (Perry et al., 2013). Chicago police used data from 426 people likely to be linked to gun violence. However, the system does not make perfect prediction and the police have arrested a lot of people who are innocent and there was no way to use this prediction in the field. Moreover, it has also failed to reduce gun violence in Chicago through this system (Saunders et al., 2016). The fundamental purpose of data science, the creation of knowledge, requires a large amount of data. When data scientists collect a lot of data, they have no choice but to face privacy challenges, as described earlier (Williams & Johnstone, 2000). One might think that there should be institutional support to protect individual privacy. However, institutions (institutional support) and laws can also be one of the challenges for data scientists. The following paragraphs will describe another challenge that data scientists may encounter due to the regulation and law of data.

### Data legislations
Wall (2018) claim that as data science has been developed and widely used, there has also been an increase in data-related crimes. This trend has led to the need for data-related legislation in a number of countries. As a result, on May 25, 2018, the European Union (EU) regulations on data protection, also known as General Data Protection Regulations (GDPR), took effect (Marelli & Testa, 2018) and OECD members states have formulated and agreed on guidelines on privacy protection of personal data because differences in national laws can hinder the free flow of data (“OECD Guidelines on the Privacy and Transborder Flows of Personal Data”, n.d). Newly enacted laws and guidelines require clear privacy notices to emphasize that unlike previous data protection laws, they could affect privacy of individual (Laybats & Davies, 2018). In other words, it has become more important for individuals to agree to store and use their data. This privacy agreement may also be withdrawn at any time and should be reviewed regularly to ensure that the data is maintained. The regulation also limits artificial intelligence to making decisions because of algorithms without human intervention (Jones & Dages, 2003). Data scientists may have to consider more than before. The main principle of the GDPR is that data scientists should process data legally, clarify the purpose of data operations, cannot store and own data more than necessary, and ensure that data is not erroneous or misleading. They should also pay special attention to data security (Marelli & Testa, 2018). For example, Companies, government departments, and various institutions affected by the new regulations have invested heavily in establishing specialized departments, training professional personnel, and preparing implementation codes and tools to ensure that they are aware of and comply with the regulations. A number of wholesalers and retail customers were also concerned that the regulation would lead to a drop in their sales and income (Jones & Dages, 2003). Data laws to encourage and protect data science may actually reduce the scope of data science. However, these legal challenges of data scientists are appropriate regulations and essential at the era of big data. Furthermore, In the future, there is also a possibility that more data-related crimes and problems that are out of line with these rules will increase, and other new responsibilities and challenges may come to data scientists. Therefore, data scientists should be willing to accept the legal challenges they face in creating knowledge through data science.

### Conclusion
Data science has a huge impact on almost every social part, and it is expected to expand (Maneth & Poulovassilis, 2017). Thus, the ethical and legal responsibilities of data scientists are growing (Floridi & Taddeo, 2016). In this process, data scientists experience several challenges. For example, unanticipated discrimination may arise due to neglect of the validity of data in the Electronic Recruitment System (Sylva & Mol, 2009), and there is a privacy issue in which individual data is used in the name of maintaining power or curbing crime (Hu, 2019; Norris et al., 2016). Recognizing these problems, the European Union and member states of the Organization for Economic Cooperation and Development are enacting data-related laws to protect data from individuals and organizations and encourage legitimate distribution, but these regulations and data-related laws may pose another challenge to activities of data scientists (Marelli & Testa, 2018). However, at a time when data science is becoming a new emerging sector, it should be natural and encouraged to enact these regulations and data scientists should pay close attention to their challenges such as data validity, privacy and data-related laws that can be easily ignored.

### References
Amazon ditched AI recruiting tool that favored men for technical jobs. (2018, October 11). The Guardian. Retrieved from https://www.theguardian.com/technology/2018/oct/10/amazon-hiring-ai-gender-bias-recruiting-engine

Boyd, D., & Crawford, K. (2012). CRITICAL QUESTIONS FOR BIG DATA: Provocations for a cultural, technological, and scholarly phenomenon. Information, Communication & Society, 15(5), 662-679.

Cheng, C., Cowling, B., Lau, E., Ho, L., Leung, G., & Ip, D. (2012). Electronic School Absenteeism Monitoring and Influenza Surveillance, Hong Kong. Emerging Infectious Diseases, 18(5), 885-887.

Davies, S. G. (2016). CCTV: A new battleground for privacy. In Surveillance, Closed Circuit Television and Social Control (pp. 243-254). Taylor and Francis.

Di Zio, M., Fursova, N., Gelsema, T., Gießing, S., Guarnera, U., Petrauskienė, J., ... & Walsdorfer, K. (2017). Methodology for data validation 1.0. 

Faliagka, E., Sirmakessis, S., & Rigou, M. (2015). An e-recruitment system exploiting candidates’ social presence. Lecture Notes in Computer Science (including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 9396, 153-162.

Floridi, L., & Taddeo, M. (2016). What is data ethics? Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences, 374(2083), Philosophical transactions. Series A, Mathematical, physical, and engineering sciences, December 28, 2016, Vol.374(2083).

Greenleaf, G. (2014). Standards by Which to Assess a Country’s Data Privacy Laws. In Asian Data Privacy Laws (p. Asian Data Privacy Laws, Chapter 3). Oxford University Press.

Grindrod, P. (2016). Beyond privacy and exposure: Ethical issues within citizen-facing analytics. Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences, 374(2083), Philosophical transactions. Series A, Mathematical, physical, and engineering sciences, December 28, 2016, Vol.374(2083).

Hu, C. (2019, September 12). What Hong Kong's masked protesters fear. CNN world. Retrieved from https://edition.cnn.com/2019/09/09/asia/smart-lamp-hong-kong-hnk-intl/index.html

Jones, J., & Dages, K. (2003). Technology Trends in Staffing and Assessment: A Practice Note. International Journal of Selection and Assessment, 11(2-3), 247-252.

Kroener, I. (2013). 'Caught on Camera': The Media Representation of Video Surveillance in Relation to the 2005 London Underground Bombings. Surveillance & Society, 11(1-2), 121-133.

Laybats, C., & Davies, J. (2018). GDPR: Implementing the regulations. Business Information Review, 35(2), 81-83. 

Marelli, L., & Testa, G. (2018). Scrutinizing the EU General Data Protection Regulation. Science (New York, N.Y.), 360(6388), 496-498.

Maneth, S., & Poulovassilis, A. (2017). Data science. Computer Journal, 60(3), 285-286. 

Menichelli, F., & Kitchin, R. (2015). The data revolution: Big data, open data, data infrastructures and their consequences. Surveillance and Society, 13(2), 319-321. 

Norris, C., & Mccahill, M. (2006). CCTV: Beyond penal modernism? British Journal Of Criminology, 46(1), 97-118. 

Norris, C., Moran, J., & Armstrong, G. (2016). Surveillance, closed circuit television and social control. London, England ; New York, New York: Routledge.

OECD Guidelines on the Protection of Privacy and Transborder Flows of Personal Data. (n.d.). Retrieved from http://www.oecd.org/sti/ieconomy/oecdguidelinesontheprotectionofprivacyandtransborderflowsofpersonaldata.htm

Perry, W., Mcinnis, B., Price, C., Smith, S., & Hollywood, J. (2013). Predictive Policing. RAND Corporation.

Pfieffelmann, B., Wagner, S., & Libkuman, T. (2010). Recruiting on Corporate Web Sites: Perceptions of fit and attraction. International Journal of Selection and Assessment, 18(1), 40-47.

Saunders, J., Hunt, P., & Hollywood, J. (2016). Predictions put into practice: A quasi-experimental evaluation of Chicago’s predictive policing pilot. Journal of Experimental Criminology, 12(3), 347-371.

Sylva, H., & Mol, S. (2009). E-Recruitment: A study into applicant perceptions of an online application system. International Journal Of Selection And Assessment, 17(3), 311-323.

Viswesvaran, C. (2003). Introduction to Special Issue: Role of Technology in Shaping the Future of Staffing and Assessment. International Journal of Selection and Assessment, 11(2-3), 107-111.

Wall, D. (2018). How Big Data Feeds Big Crime. Current History, 117(795), 29-34.

Welsh, B., Farrington, David P., & Great Britain. Home Office. Research, Development Statistics Directorate. (2002). Crime prevention effects of closed circuit television : A systematic review (Home Office research studies; 252). London: Home Office.

Williams, K. S., & Johnstone, C. (2000). The politics of the selective gaze: Closed Circuit Television and the policing of public space. Crime, Law and Social Change, 34(2), 183-210.
